{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class 10 - Image encoding and classification using CNNs and ViTs\n",
    "In this class, we will use pretrained CNN and transformer models to encode and classify images.\n",
    "We will use a library you are familiar with, namely Hugging Face's _transformers_, as well as (under the hood) _timm_ (another HuggingFace library, specific to computer vision) and _pytorch_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "**Overall goal**: training a simple fully-connected neural network that classifies snack types from this dataset (https://huggingface.co/datasets/Matthijs/snacks) based on image embeddings extracted from a pretrained ResNet model (https://arxiv.org/abs/1512.03385)\n",
    "\n",
    "**Suggestion**: use `example.ipynb` notebook if you are in doubt! This might be especially helpful with respect to Pytorch. All we will use Pytorch for, here, are things we already did as part of NLP, but if you have not used Pytorch since it is perfectly understandable that you need a reminder.\n",
    "\n",
    "Steps:\n",
    "1. Use Hugging Face's `dataset` library to import the dataset: https://huggingface.co/datasets/Matthijs/snacks. Import the training and the test splits from this dataset, and visualize the frequency of each class.\n",
    "2. Load a pretrained ResNet model using HuggingFace's `transformers`. Check the documentation (https://huggingface.co/docs/transformers/en/model_doc/resnet, https://huggingface.co/microsoft/resnet-50) for more details on how to load the model. Visualize the structure of the model, and reflect on how each of the blocks works, based on what we discussed in the lecture;\n",
    "3. Extract ResNet embeddings for all the images in the training set and all the images in the test set. You will need to look for the `pooler_output` attribute of the model's output. This sounds complex, but it's really just a minor change over the examples presented in the model's documentation;\n",
    "4. Optional: apply dimensionality reduction to the embeddings using TSNE (https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html): is any information about the labels encoded in the embeddings?\n",
    "5. Train a simple neural network that, for each image in the training set, takes the embeddings as inputs and predicts the snack label\n",
    "    - You will have to create a Pytorch `Dataset` (https://pytorch.org/tutorials/beginner/basics/data_tutorial.html) where both your embeddings and your labels are included.\n",
    "    - You will also have to create a `Dataloader` for the training set, as this will make it much easier to do things like batching and shuffling\n",
    "    - You need to specify the loss and the optimizer\n",
    "    - Then, you need to specify a training loop. Remember the neural net gymnastics:\n",
    "        - Do the forward step, i.e., make a prediction\n",
    "        - Compute the loss based on predictions and true labels \n",
    "        - Compute gradients\n",
    "        - Propagate gradients (backpropagation)\n",
    "6. Evaluate the resulting model:\n",
    "    - Make predictions for all examples in the test set\n",
    "    - Use `sklearn.metrics` utils (https://scikit-learn.org/stable/modules/model_evaluation.html#classification-metrics) to compute accuracy and F1-score\n",
    "    - Also plot the confusion matrix, to see which categories are most often confused\n",
    "7. Explore zero-shot classification for computer vision\n",
    "    - Try classification on custom labels on one of the images from today's dataset. To do so, adapt the code provided here: https://huggingface.co/docs/transformers/en/tasks/zero_shot_image_classification, by simply replacing the desired labels and the input\n",
    "    - Can you get reasonable predictions on more nuanced labels than the ones provided with the dataset?\n",
    "    - Which kind of models support this behavior? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from collections import Counter\n",
    "\n",
    "from transformers import AutoImageProcessor, ResNetModel\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from torchview import draw_graph\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and inspecting data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset snacks (file:///home/ucloud/.cache/huggingface/datasets/Matthijs___snacks/default/0.0.1/c0ce49075aa469a098a5f2e3455941c894e02e1c9bf642d4d33e6c51460ff590)\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "Loading a dataset cached in a LocalFileSystem is not supported.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/work/LauraWulffPaaby#7567/DatSci_24_forked/DataSci-AU-24/nbs/class_10/exercise_ANSWER.ipynb Cell 5\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell://app-5037463-0.cloud.sdu.dk/work/LauraWulffPaaby%237567/DatSci_24_forked/DataSci-AU-24/nbs/class_10/exercise_ANSWER.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#dataset = load_dataset(\"Matthijs/snacks\")\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://app-5037463-0.cloud.sdu.dk/work/LauraWulffPaaby%237567/DatSci_24_forked/DataSci-AU-24/nbs/class_10/exercise_ANSWER.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m dataset_name \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mMatthijs/snacks\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell://app-5037463-0.cloud.sdu.dk/work/LauraWulffPaaby%237567/DatSci_24_forked/DataSci-AU-24/nbs/class_10/exercise_ANSWER.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m data \u001b[39m=\u001b[39m load_dataset(dataset_name)\n",
      "File \u001b[0;32m/work/LauraWulffPaaby#7567/DatSci_24_forked/DataSci-AU-24/venv_dat_sci24/lib/python3.10/site-packages/datasets/load.py:1810\u001b[0m, in \u001b[0;36mload_dataset\u001b[0;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, ignore_verifications, keep_in_memory, save_infos, revision, use_auth_token, task, streaming, num_proc, storage_options, **config_kwargs)\u001b[0m\n\u001b[1;32m   1806\u001b[0m \u001b[39m# Build dataset for splits\u001b[39;00m\n\u001b[1;32m   1807\u001b[0m keep_in_memory \u001b[39m=\u001b[39m (\n\u001b[1;32m   1808\u001b[0m     keep_in_memory \u001b[39mif\u001b[39;00m keep_in_memory \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m is_small_dataset(builder_instance\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39mdataset_size)\n\u001b[1;32m   1809\u001b[0m )\n\u001b[0;32m-> 1810\u001b[0m ds \u001b[39m=\u001b[39m builder_instance\u001b[39m.\u001b[39;49mas_dataset(split\u001b[39m=\u001b[39;49msplit, verification_mode\u001b[39m=\u001b[39;49mverification_mode, in_memory\u001b[39m=\u001b[39;49mkeep_in_memory)\n\u001b[1;32m   1811\u001b[0m \u001b[39m# Rename and cast features to match task schema\u001b[39;00m\n\u001b[1;32m   1812\u001b[0m \u001b[39mif\u001b[39;00m task \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/work/LauraWulffPaaby#7567/DatSci_24_forked/DataSci-AU-24/venv_dat_sci24/lib/python3.10/site-packages/datasets/builder.py:1107\u001b[0m, in \u001b[0;36mDatasetBuilder.as_dataset\u001b[0;34m(self, split, run_post_process, verification_mode, ignore_verifications, in_memory)\u001b[0m\n\u001b[1;32m   1105\u001b[0m is_local \u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m is_remote_filesystem(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fs)\n\u001b[1;32m   1106\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_local:\n\u001b[0;32m-> 1107\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mLoading a dataset cached in a \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fs)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m is not supported.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output_dir):\n\u001b[1;32m   1109\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(\n\u001b[1;32m   1110\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDataset \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m: could not find data in \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output_dir\u001b[39m}\u001b[39;00m\u001b[39m. Please make sure to call \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1111\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mbuilder.download_and_prepare(), or use \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1112\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdatasets.load_dataset() before trying to access the Dataset object.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1113\u001b[0m     )\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Loading a dataset cached in a LocalFileSystem is not supported."
     ]
    }
   ],
   "source": [
    "snack_data = load_dataset(\"Matthijs/snacks\") # from huggingface datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label dictionary: inferred from the dataset's online documentation\n",
    "label_dict = {0: 'apple',\n",
    "              1: 'banana',\n",
    "              2: 'cake',\n",
    "              3: 'candy',\n",
    "              4: 'carrot',\n",
    "              5: 'cookie',\n",
    "              6: 'doughnut',\n",
    "              7: 'grape',\n",
    "              8: 'hotdog',\n",
    "              9: 'icecream',\n",
    "              10: 'juice',\n",
    "              11: 'muffin',\n",
    "              12: 'orange',\n",
    "              13: 'pineapple',\n",
    "              14: 'popcorn',\n",
    "              15: 'pretzel',\n",
    "              16: 'salad',\n",
    "              17: 'strawberry',\n",
    "              18: 'waffle',\n",
    "              19: 'watermelon'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bonus CV tasks\n",
    "- Try training a classifier on embeddings extracted from a vision transformer: how does performance compare to ResNet?\n",
    "- Build a CNN from scratch for this classification task: how does performance compare? There are lots of tutorials online, you can start from this one: https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html.\n",
    "- Look up models and pipelines for more computer vision tasks, including semantic segmentation, object detection (which can also be performed zero-shot using ViT), etc.\n",
    "\n",
    "#### Bonus NN-related tasks\n",
    "- Train NN-based models (FFNNs or RNNs) on the bike data: how does performance compare to the best algorithms?\n",
    "\n",
    "### Additional tasks\n",
    "- A wide array of pretrained models for audio classification (including zero-shot audio classification) are also available on Hugging Face. Experiment with those :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional notes\n",
    "- Here, we worked with pretrained models. If you want to train a CNN from scratch (e.g., because you are working with \"special\" image data, and no pretrained models are available), you can look up, for example, _Pytorch_'s intro tutorial (https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html). There are really a billion resources online if this is what you decide to focus on for your final project;\n",
    "- If, instead, fine-tuning a full model is what you want to do, plenty of tutorials are available for tasks ranging from image classification, object detection, image segmentation, etc. Look up _timm_'s documentation (https://huggingface.co/docs/hub/en/timm) and _transformers_'s documentation (https://huggingface.co/docs/transformers/tasks/image_classification)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_dat_sci24",
   "language": "python",
   "name": "venv_dat_sci24"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
